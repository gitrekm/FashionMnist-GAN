{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tfgpu] *",
      "language": "python",
      "name": "conda-env-tfgpu-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "DCGAN-fashion-MNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitrekm/FashionMnist-GAN/blob/master/DCGAN_fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7WmgjQm2ho7",
        "colab_type": "text"
      },
      "source": [
        "## Deep Convolutional Generative Adversarial Networks Trained on Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nddHzcjY2ho_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import all required packages\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDCByZnS2hpM",
        "colab_type": "text"
      },
      "source": [
        "### Load and Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_9kudax2hpP",
        "colab_type": "code",
        "outputId": "1a8907e3-c9d7-4661-879d-7019caf434dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "(train_imgs, train_lab), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_imgs = train_imgs.reshape(train_imgs.shape[0], 28, 28, 1).astype('float32')\n",
        "train_imgs = (train_imgs - 127.5) / 127.5 # Normalize the images in between -1 and 1\n",
        "\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAL85gov2hpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch and Shuffle the data\n",
        "\n",
        "train_set = tf.data.Dataset.from_tensor_slices(train_imgs).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqlO-qNY2hph",
        "colab_type": "text"
      },
      "source": [
        "### Define the architectures for generator and discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX5Y7hEd2hpj",
        "colab_type": "code",
        "outputId": "9b735a77-7bc0-4fb9-b282-ab414c73e7d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Architecture for Generator\n",
        "\n",
        "def generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) #None refers to the batch size\n",
        "\n",
        "    # Conv2DTranspose are used to upsample for generating an image from a seed which is random noise\n",
        "    model.add(layers.Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_img = generator(noise, training=False)\n",
        "\n",
        "#plt.imshow(generated_img[0,:,:,0], cmap='gray')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxN7-mjo2hpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Architecture for Discriminator Model\n",
        "\n",
        "def discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[28,28,1]))\n",
        "\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128,(5,5), strides=(2,2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSF2kugR2hp8",
        "colab_type": "code",
        "outputId": "818919ef-aae9-4d9b-9cc2-60f7ed6eab6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "discriminator = discriminator_model()\n",
        "\n",
        "decision_output = discriminator(generated_img)\n",
        "\n",
        "print(decision_output)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"sequential_1/dense_1/BiasAdd:0\", shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni-bPmNp2hqE",
        "colab_type": "text"
      },
      "source": [
        "### Define loss and optimizers for our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ovFc36M2hqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute CrossEntropyLoss\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UUMZFO02hqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define discriminator loss\n",
        "\n",
        "def discriminator_loss(true_output, fake_output):\n",
        "    true_loss = cross_entropy(tf.ones_like(true_output), true_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    tot_loss = true_loss + fake_loss\n",
        "    return tot_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg_W30WH2hqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Generator loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y0JFnsy2hqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining separate optimizers for generator and discriminator\n",
        "gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "dis_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGGm_ajX2hqi",
        "colab_type": "text"
      },
      "source": [
        "### Saving Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxPY4VvH2hqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoints_dir = './training_chpk'\n",
        "checkpoint_prefix = os.path.join(checkpoints_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(gen_optimizer=gen_optimizer, dis_optimizer=dis_optimizer, generator=generator, discriminator=discriminator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIgTyHqV2hqt",
        "colab_type": "text"
      },
      "source": [
        "### Define number of epochs and examples to generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUPdWMJc2hqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 60\n",
        "\n",
        "noise_dim = 100\n",
        "num_ex_to_gen = 16\n",
        "\n",
        "seed = tf.random.normal([num_ex_to_gen,noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhNo685t2hqy",
        "colab_type": "text"
      },
      "source": [
        "The training begins with generator given a random seed as an input which is used to generate an image. The role of discriminator is to compare true image from training set with the fake image from generator. The loss is then calculated for both the models and weights are then updated through gradient descent. As we proceed further we will be having an efficient generator that is able to generate fake images close to the true images and an accurate discriminator that is able to accurately distinguish fake images from true images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OOkGLTe2hqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_img = generator(noise, training=True)\n",
        "\n",
        "        true_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_img, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(true_output, fake_output)\n",
        "\n",
        "    grad_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    grad_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    gen_optimizer.apply_gradients(zip(grad_generator, generator.trainable_variables))\n",
        "    dis_optimizer.apply_gradients(zip(grad_discriminator, discriminator.trainable_variables))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5P5XpV02hq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for img_batch in dataset:\n",
        "            train_step(img_batch)\n",
        "\n",
        "        #produce images for the GIF as we go\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "        # Save the model every 12 EPOCHS\n",
        "        if (epoch + 1) % 12 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "        # Generator after final epoch\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator, epochs, seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBTVHpgO2hrB",
        "colab_type": "text"
      },
      "source": [
        "### Generate and save images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4reZXHnz2hrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "\n",
        "    # Training set to false so that every layer runs in inferenc mode\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CC_ERuv2hrL",
        "colab_type": "text"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW_TUhRu2hrN",
        "colab_type": "code",
        "outputId": "bf2423c8-cae1-4586-d2c0-91e03cb335d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%time\n",
        "train(train_set, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function train_step at 0x7f141741c0d0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_step at 0x7f141741c0d0>: AttributeError: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function train_step at 0x7f141741c0d0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_step at 0x7f141741c0d0>: AttributeError: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0hHW2F-2hrT",
        "colab_type": "text"
      },
      "source": [
        "### Restore the latest checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9ZwZ0942hrU",
        "colab_type": "code",
        "outputId": "ab59fc1d-05d2-440f-d815-d7ce888e40bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoints_dir))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d1abcbed4aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'checkpoint' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE9r3Sb82hre",
        "colab_type": "text"
      },
      "source": [
        "### Create a gif animation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh8ArSVZ2hrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_file = 'fmdcgan.gif'\n",
        "\n",
        "with imageio.get_writer(out_file, mode='I') as writer:\n",
        "    filenames = glob.glob('image*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    last = -1\n",
        "    for i, filename in enumerate(filenames):\n",
        "        frame = 2*(i**0.5)\n",
        "        if round(frame) > round(last):\n",
        "            last = frame\n",
        "        else:\n",
        "            continue\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "\n",
        "    import IPython\n",
        "    if IPython.version_info > (6,2,0,''):\n",
        "        display.Image(filename=out_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzX2dWnS2hr0",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/anishreddy3/Fashion-MNIST-GAN-Keras/blob/master/fmdcgan.gif?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY_iGkz02hr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}